import torch
import os  # for deleting excess files generated by triton
from math import log2
import time

import triton
import triton.language as tl
from triton.runtime import driver
import numpy as np

from utils import GenerateLinkedList

# Device properties
DEVICE = torch.device(f"cuda:{torch.cuda.current_device()}")
properties = driver.active.utils.get_device_properties(DEVICE.index)
NUM_SM = properties["multiprocessor_count"]
WARP_SIZE = properties["warpSize"]

# Kernels
@triton.jit
def add_kernel(x_ptr, y_ptr, output_ptr, n_elements, BLOCK_SIZE: tl.constexpr):
    pid = tl.program_id(axis=0)
    block_start = pid * BLOCK_SIZE
    offsets = block_start + tl.arange(0, BLOCK_SIZE)
    mask = offsets < n_elements
    x = tl.load(x_ptr + offsets, mask=mask)
    y = tl.load(y_ptr + offsets, mask=mask)
    tl.store(output_ptr + offsets, x + y, mask=mask)

@triton.jit
def fast_ll_transversal(linked_list, n_elements, BLOCK_SIZE: tl.constexpr):
    pid = tl.program_id(axis=0)
    block_start = pid * BLOCK_SIZE
    offsets = block_start + tl.arange(0, BLOCK_SIZE)
    mask = offsets < n_elements
    curr_ptr = linked_list + offsets
    curr_node = tl.load(curr_ptr, mask=mask, other=-1)
    next_node = tl.load(linked_list + curr_node, mask=mask, other=-1)
    valid = (next_node != -1) & (curr_node != next_node)
    tl.store(curr_ptr, next_node, mask=mask & valid)

# Tuning functions
def tune_block_size_add(size, candidates, num_iters=5):
    x = torch.rand(size, device=DEVICE)
    y = torch.rand(size, device=DEVICE)
    output = torch.empty_like(x)
    best_time = float('inf')
    best_bs = None
    for bs in candidates:
        grid = lambda meta: (triton.cdiv(size, bs),)
        # warm-up
        add_kernel[grid](x, y, output, size, BLOCK_SIZE=bs)
        torch.cuda.synchronize()
        # timing
        start = torch.cuda.Event(enable_timing=True)
        end = torch.cuda.Event(enable_timing=True)
        start.record()
        for _ in range(num_iters):
            add_kernel[grid](x, y, output, size, BLOCK_SIZE=bs)
        end.record()
        torch.cuda.synchronize()
        elapsed = start.elapsed_time(end) / num_iters
        print(f"BLOCK_SIZE={bs}, avg time={elapsed:.3f} ms")
        if elapsed < best_time:
            best_time = elapsed
            best_bs = bs
    print(f"Best BLOCK_SIZE for add: {best_bs} (avg {best_time:.3f} ms)")
    return best_bs


def tune_block_size_ll(ll_tensor, size, candidates, num_iters=3):
    best_time = float('inf')
    best_bs = None
    for bs in candidates:
        grid = ((size + bs - 1) // bs,)
        # warm-up
        fast_ll_transversal[grid](ll_tensor, size, bs)
        torch.cuda.synchronize()
        # timing
        start = torch.cuda.Event(enable_timing=True)
        end = torch.cuda.Event(enable_timing=True)
        start.record()
        for _ in range(num_iters):
            fast_ll_transversal[grid](ll_tensor, size, bs)
        end.record()
        torch.cuda.synchronize()
        elapsed = start.elapsed_time(end) / num_iters
        print(f"BLOCK_SIZE={bs}, avg time={elapsed:.3f} ms")
        if elapsed < best_time:
            best_time = elapsed
            best_bs = bs
    print(f"Best BLOCK_SIZE for linked-list: {best_bs} (avg {best_time:.3f} ms)")
    return best_bs

# Examples
class HelloWorld:
    def add(self, x: torch.Tensor, y: torch.Tensor, BLOCK_SIZE=1024):
        output = torch.empty_like(x)
        n = x.numel()
        grid = lambda meta: (triton.cdiv(n, BLOCK_SIZE),)
        add_kernel[grid](x, y, output, n, BLOCK_SIZE=BLOCK_SIZE)
        torch.cuda.synchronize()
        return output

class FastLinkedList:
    @staticmethod
    def gpu_compute(ll_tensor, size, BLOCK_SIZE):
        grid = ((size + BLOCK_SIZE - 1) // BLOCK_SIZE,)
        depth = int(log2(size)) + 1
        for _ in range(depth):
            fast_ll_transversal[grid](ll_tensor, size, BLOCK_SIZE)
        torch.cuda.synchronize()

# Argument parsing and main
if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="Triton examples with auto-tuning")
    parser.add_argument("--example", choices=["add", "linked_list"], default="add",
                        help="Which example to run")
    parser.add_argument("--size", type=int, default=1<<20, help="Size of the data")
    parser.add_argument("--block-size", type=int, help="Block size (power of two)")
    parser.add_argument("--auto-tune", action="store_true", help="Auto-tune block size")
    args = parser.parse_args()

    if args.example == "add":
        if args.auto_tune:
            candidates = [32, 64, 128, 256, 512, 1024]
            best_bs = tune_block_size_add(args.size, candidates)
        else:
            bs = args.block_size or 1024
            x = torch.rand(args.size, device=DEVICE)
            y = torch.rand(args.size, device=DEVICE)
            out = HelloWorld().add(x, y, BLOCK_SIZE=bs)
            print("Result sample:", out[:10])
    else:
        ll_tensor, head = GenerateLinkedList(size=args.size, cudaTensor=True)
        if args.auto_tune:
            candidates = [32, 64, 128, 256]
            best_bs = tune_block_size_ll(ll_tensor.clone(), args.size, candidates)
        else:
            bs = args.block_size or 32
            FastLinkedList.gpu_compute(ll_tensor, args.size, bs)
            print("Final linked list head pointers sample:", ll_tensor[:10])
